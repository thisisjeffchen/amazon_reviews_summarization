Batch: 
64
Device: 
0
/home/ubuntu/anaconda3/envs/tf_nightly/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2019-04-16 22:37:32.755847: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-16 22:37:32.763313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-16 22:37:32.850220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-16 22:37:32.851056: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568c4c2a390 executing computations on platform CUDA. Devices:
2019-04-16 22:37:32.851083: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-04-16 22:37:32.853802: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300050000 Hz
2019-04-16 22:37:32.854512: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568c4c9aab0 executing computations on platform Host. Devices:
2019-04-16 22:37:32.854534: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-16 22:37:32.854841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1589] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-04-16 22:37:32.854864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:37:32.854924: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-16 22:37:32.855651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:37:32.855671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:37:32.855679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:37:32.855951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
W0416 22:37:32.863586 140288008099584 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:250: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0416 22:37:32.870144 140288008099584 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:257: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0416 22:37:32.878138 140288008099584 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:129: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0416 22:37:33.125111 140288008099584 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:261: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.max_pooling2d instead.
W0416 22:37:36.794721 140288008099584 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2250: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-04-16 22:37:37.254015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:37:37.254094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:37:37.254105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:37:37.254113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:37:37.254398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2019-04-16 22:37:37.882022: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1364] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0416 22:37:38.577201 140288008099584 session_manager.py:500] Running local_init_op.
I0416 22:37:38.632026 140288008099584 session_manager.py:502] Done running local_init_op.
2019-04-16 22:37:40.340862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-04-16 22:37:40.531045: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
TensorFlow:  1.14
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  64 global
             64 per device
Num batches: 100
Num epochs:  0.00
Devices:     ['/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 56.6 +/- 0.0 (jitter = 0.0)	8.220
10	images/sec: 56.6 +/- 0.0 (jitter = 0.1)	7.880
20	images/sec: 56.4 +/- 0.1 (jitter = 0.2)	7.910
30	images/sec: 56.3 +/- 0.1 (jitter = 0.4)	7.820
40	images/sec: 56.2 +/- 0.1 (jitter = 0.4)	8.004
50	images/sec: 56.1 +/- 0.1 (jitter = 0.4)	7.768
60	images/sec: 56.0 +/- 0.0 (jitter = 0.4)	8.116
70	images/sec: 56.0 +/- 0.0 (jitter = 0.3)	7.817
80	images/sec: 55.9 +/- 0.0 (jitter = 0.3)	7.978
90	images/sec: 55.9 +/- 0.0 (jitter = 0.3)	8.093
100	images/sec: 55.9 +/- 0.0 (jitter = 0.3)	8.027
----------------------------------------------------------------
total images/sec: 55.88
----------------------------------------------------------------

real	2m20.789s
user	0m25.756s
sys	0m4.236s
Batch: 
64
Device: 
0
===USE FP16===
/home/ubuntu/anaconda3/envs/tf_nightly/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2019-04-16 22:39:53.503355: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-16 22:39:53.510824: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-16 22:39:53.589642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-16 22:39:53.590971: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55747bfb80e0 executing computations on platform CUDA. Devices:
2019-04-16 22:39:53.591007: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-04-16 22:39:53.593697: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300050000 Hz
2019-04-16 22:39:53.593923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55747c028800 executing computations on platform Host. Devices:
2019-04-16 22:39:53.593948: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-16 22:39:53.594307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1589] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-04-16 22:39:53.594338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:39:53.594406: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-16 22:39:53.595179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:39:53.595208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:39:53.595217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:39:53.595494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
W0416 22:39:53.607007 139755793086208 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:250: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0416 22:39:53.613667 139755793086208 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:257: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0416 22:39:53.622611 139755793086208 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:129: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0416 22:39:53.874329 139755793086208 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:261: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.max_pooling2d instead.
W0416 22:39:57.988932 139755793086208 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2250: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-04-16 22:39:58.483022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:39:58.483115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:39:58.483130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:39:58.483152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:39:58.483471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2019-04-16 22:39:59.134141: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1364] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0416 22:39:59.824054 139755793086208 session_manager.py:500] Running local_init_op.
I0416 22:39:59.883450 139755793086208 session_manager.py:502] Done running local_init_op.
2019-04-16 22:40:01.833829: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-04-16 22:40:02.029568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
TensorFlow:  1.14
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  64 global
             64 per device
Num batches: 100
Num epochs:  0.00
Devices:     ['/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 64.8 +/- 0.0 (jitter = 0.0)	8.110
10	images/sec: 64.7 +/- 0.0 (jitter = 0.2)	7.754
20	images/sec: 64.7 +/- 0.0 (jitter = 0.1)	7.911
30	images/sec: 64.6 +/- 0.0 (jitter = 0.3)	7.773
40	images/sec: 64.6 +/- 0.0 (jitter = 0.2)	7.915
50	images/sec: 64.6 +/- 0.0 (jitter = 0.2)	7.884
60	images/sec: 64.6 +/- 0.0 (jitter = 0.2)	7.701
70	images/sec: 64.6 +/- 0.0 (jitter = 0.2)	8.003
80	images/sec: 64.6 +/- 0.0 (jitter = 0.2)	7.778
90	images/sec: 64.6 +/- 0.0 (jitter = 0.2)	7.799
100	images/sec: 64.6 +/- 0.0 (jitter = 0.2)	8.038
----------------------------------------------------------------
total images/sec: 64.59
----------------------------------------------------------------

real	2m4.658s
user	0m24.960s
sys	0m4.104s
Batch: 
96
Device: 
0
/home/ubuntu/anaconda3/envs/tf_nightly/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2019-04-16 22:41:58.130007: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-16 22:41:58.137375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-16 22:41:58.216639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-16 22:41:58.217493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556550d6f050 executing computations on platform CUDA. Devices:
2019-04-16 22:41:58.217529: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-04-16 22:41:58.220683: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300050000 Hz
2019-04-16 22:41:58.220907: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556550ddf780 executing computations on platform Host. Devices:
2019-04-16 22:41:58.220938: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-16 22:41:58.221272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1589] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-04-16 22:41:58.221308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:41:58.221393: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-16 22:41:58.222178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:41:58.222211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:41:58.222229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:41:58.222503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
W0416 22:41:58.230480 140665869489920 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:250: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0416 22:41:58.237195 140665869489920 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:257: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0416 22:41:58.245388 140665869489920 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:129: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0416 22:41:58.495007 140665869489920 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:261: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.max_pooling2d instead.
W0416 22:42:02.219714 140665869489920 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2250: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-04-16 22:42:02.690918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:42:02.691008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:42:02.691022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:42:02.691031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:42:02.691332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2019-04-16 22:42:03.324867: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1364] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0416 22:42:04.019685 140665869489920 session_manager.py:500] Running local_init_op.
I0416 22:42:04.073534 140665869489920 session_manager.py:502] Done running local_init_op.
2019-04-16 22:42:05.738761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-04-16 22:42:05.928313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
TensorFlow:  1.14
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  96 global
             96 per device
Num batches: 100
Num epochs:  0.01
Devices:     ['/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 56.1 +/- 0.0 (jitter = 0.0)	7.940
10	images/sec: 56.2 +/- 0.0 (jitter = 0.1)	7.722
20	images/sec: 56.2 +/- 0.0 (jitter = 0.1)	7.965
30	images/sec: 56.3 +/- 0.0 (jitter = 0.1)	7.869
40	images/sec: 56.3 +/- 0.0 (jitter = 0.1)	7.936
50	images/sec: 56.3 +/- 0.0 (jitter = 0.1)	7.832
60	images/sec: 56.3 +/- 0.0 (jitter = 0.1)	7.832
70	images/sec: 56.4 +/- 0.0 (jitter = 0.1)	7.889
80	images/sec: 56.4 +/- 0.0 (jitter = 0.1)	7.872
90	images/sec: 56.4 +/- 0.0 (jitter = 0.1)	7.873
100	images/sec: 56.4 +/- 0.0 (jitter = 0.1)	7.913
----------------------------------------------------------------
total images/sec: 56.38
----------------------------------------------------------------

real	3m23.975s
user	0m30.636s
sys	0m5.772s
Batch: 
96
Device: 
0
===USE FP16===
/home/ubuntu/anaconda3/envs/tf_nightly/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2019-04-16 22:45:22.124207: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-16 22:45:22.131782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-16 22:45:22.211100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-16 22:45:22.211992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e39c114e80 executing computations on platform CUDA. Devices:
2019-04-16 22:45:22.212028: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-04-16 22:45:22.214735: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300050000 Hz
2019-04-16 22:45:22.214961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e39c1855e0 executing computations on platform Host. Devices:
2019-04-16 22:45:22.214990: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-16 22:45:22.215819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1589] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-04-16 22:45:22.215850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:45:22.215937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-16 22:45:22.216712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:45:22.216741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:45:22.216751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:45:22.217017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
W0416 22:45:22.227718 140104339719936 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:250: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0416 22:45:22.234333 140104339719936 deprecation.py:237] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/models/model.py:257: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0416 22:45:22.243257 140104339719936 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:129: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0416 22:45:22.492424 140104339719936 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:261: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.max_pooling2d instead.
W0416 22:45:26.569281 140104339719936 deprecation.py:323] From /home/ubuntu/projects/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2250: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-04-16 22:45:27.066012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1712] Adding visible gpu devices: 0
2019-04-16 22:45:27.066105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 22:45:27.066118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126]      0 
2019-04-16 22:45:27.066126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1139] 0:   N 
2019-04-16 22:45:27.066402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1260] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2019-04-16 22:45:27.686768: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1364] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0416 22:45:28.378216 140104339719936 session_manager.py:500] Running local_init_op.
I0416 22:45:28.438195 140104339719936 session_manager.py:502] Done running local_init_op.
2019-04-16 22:45:30.326883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-04-16 22:45:30.520001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
TensorFlow:  1.14
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  96 global
             96 per device
Num batches: 100
Num epochs:  0.01
Devices:     ['/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 66.2 +/- 0.0 (jitter = 0.0)	7.733
10	images/sec: 66.0 +/- 0.1 (jitter = 0.1)	8.016
20	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	8.174
30	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.922
40	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.927
50	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.811
60	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.884
70	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.717
80	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.984
90	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.656
100	images/sec: 66.1 +/- 0.0 (jitter = 0.2)	7.776
----------------------------------------------------------------
total images/sec: 66.11
----------------------------------------------------------------

real	2m57.033s
user	0m30.952s
sys	0m4.976s
